{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVGEqntXHZeD"
   },
   "source": [
    "# 6.2 Стекинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IREftSDTHZeE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier, ExtraTreesClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1J0r6DYGHZeH"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz', sep=',', header=None)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "i7SUi2FRHZeJ",
    "outputId": "a43c76fc-351d-422d-8835-8ef82350b647"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3   4     5    6    7    8     9   ...  45  46  47  48  49  \\\n",
       "0  2596   51   3  258   0   510  221  232  148  6279  ...   0   0   0   0   0   \n",
       "1  2590   56   2  212  -6   390  220  235  151  6225  ...   0   0   0   0   0   \n",
       "2  2804  139   9  268  65  3180  234  238  135  6121  ...   0   0   0   0   0   \n",
       "\n",
       "   50  51  52  53  54  \n",
       "0   0   0   0   0   5  \n",
       "1   0   0   0   0   5  \n",
       "2   0   0   0   0   2  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Pjzuwk_aHZeM",
    "outputId": "f5b06513-e119-4705-b6ba-1570c36569c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lYKjBKSsHZeO"
   },
   "outputs": [],
   "source": [
    "features = list(range(0, 54))\n",
    "target = 54\n",
    "\n",
    "df = df[(df[target] == 1) | (df[target] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "muwO4M4sHZeQ"
   },
   "outputs": [],
   "source": [
    "cover_train, cover_test = train_test_split(df, test_size=0.5)\n",
    "\n",
    "cover_X_train, cover_y_train = cover_train[features], cover_train[target]\n",
    "cover_X_test, cover_y_test = cover_test[features], cover_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>3268</td>\n",
       "      <td>176</td>\n",
       "      <td>12</td>\n",
       "      <td>323</td>\n",
       "      <td>38</td>\n",
       "      <td>4447</td>\n",
       "      <td>226</td>\n",
       "      <td>246</td>\n",
       "      <td>150</td>\n",
       "      <td>2418</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>3430</td>\n",
       "      <td>225</td>\n",
       "      <td>10</td>\n",
       "      <td>824</td>\n",
       "      <td>162</td>\n",
       "      <td>3535</td>\n",
       "      <td>206</td>\n",
       "      <td>250</td>\n",
       "      <td>180</td>\n",
       "      <td>306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2890</td>\n",
       "      <td>315</td>\n",
       "      <td>7</td>\n",
       "      <td>342</td>\n",
       "      <td>91</td>\n",
       "      <td>1595</td>\n",
       "      <td>201</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>1869</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>2974</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>216</td>\n",
       "      <td>49</td>\n",
       "      <td>1047</td>\n",
       "      <td>208</td>\n",
       "      <td>222</td>\n",
       "      <td>150</td>\n",
       "      <td>2192</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7285</th>\n",
       "      <td>3150</td>\n",
       "      <td>338</td>\n",
       "      <td>17</td>\n",
       "      <td>342</td>\n",
       "      <td>78</td>\n",
       "      <td>3120</td>\n",
       "      <td>182</td>\n",
       "      <td>214</td>\n",
       "      <td>171</td>\n",
       "      <td>2503</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>2974</td>\n",
       "      <td>99</td>\n",
       "      <td>22</td>\n",
       "      <td>277</td>\n",
       "      <td>-33</td>\n",
       "      <td>488</td>\n",
       "      <td>250</td>\n",
       "      <td>204</td>\n",
       "      <td>71</td>\n",
       "      <td>966</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>2890</td>\n",
       "      <td>68</td>\n",
       "      <td>17</td>\n",
       "      <td>331</td>\n",
       "      <td>-37</td>\n",
       "      <td>540</td>\n",
       "      <td>235</td>\n",
       "      <td>204</td>\n",
       "      <td>95</td>\n",
       "      <td>1884</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>3215</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>175</td>\n",
       "      <td>35</td>\n",
       "      <td>5523</td>\n",
       "      <td>204</td>\n",
       "      <td>183</td>\n",
       "      <td>105</td>\n",
       "      <td>1366</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>3221</td>\n",
       "      <td>219</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>6006</td>\n",
       "      <td>216</td>\n",
       "      <td>243</td>\n",
       "      <td>164</td>\n",
       "      <td>1622</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2679</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>268</td>\n",
       "      <td>22</td>\n",
       "      <td>309</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "      <td>136</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1419 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1   2    3    4     5    6    7    8     9   ...  44  45  46  47  \\\n",
       "9460  3268  176  12  323   38  4447  226  246  150  2418  ...   0   0   1   0   \n",
       "7852  3430  225  10  824  162  3535  206  250  180   306  ...   0   0   0   0   \n",
       "1966  2890  315   7  342   91  1595  201  234  172  1869  ...   0   0   0   0   \n",
       "1395  2974    6  10  216   49  1047  208  222  150  2192  ...   0   0   0   0   \n",
       "7285  3150  338  17  342   78  3120  182  214  171  2503  ...   1   0   0   0   \n",
       "...    ...  ...  ..  ...  ...   ...  ...  ...  ...   ...  ...  ..  ..  ..  ..   \n",
       "7129  2974   99  22  277  -33   488  250  204   71   966  ...   0   0   0   0   \n",
       "1299  2890   68  17  331  -37   540  235  204   95  1884  ...   0   0   0   0   \n",
       "1417  3215   28  23  175   35  5523  204  183  105  1366  ...   0   0   0   0   \n",
       "1418  3221  219   3  256   25  6006  216  243  164  1622  ...   0   0   0   0   \n",
       "6567  2679   38   8  268   22   309  220  222  136   900  ...   0   0   0   0   \n",
       "\n",
       "      48  49  50  51  52  53  \n",
       "9460   0   0   0   0   0   0  \n",
       "7852   0   0   0   1   0   0  \n",
       "1966   0   0   0   0   0   0  \n",
       "1395   0   0   0   0   0   0  \n",
       "7285   0   0   0   0   0   0  \n",
       "...   ..  ..  ..  ..  ..  ..  \n",
       "7129   0   0   0   0   0   0  \n",
       "1299   0   0   0   0   0   0  \n",
       "1417   0   0   0   0   0   0  \n",
       "1418   0   0   0   0   0   0  \n",
       "6567   0   0   0   0   0   0  \n",
       "\n",
       "[1419 rows x 54 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.0</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3017.875220</td>\n",
       "      <td>155.593232</td>\n",
       "      <td>12.850899</td>\n",
       "      <td>277.732464</td>\n",
       "      <td>43.927388</td>\n",
       "      <td>2583.450828</td>\n",
       "      <td>213.277053</td>\n",
       "      <td>224.611562</td>\n",
       "      <td>143.671836</td>\n",
       "      <td>2108.287980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117378</td>\n",
       "      <td>0.073669</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020092</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>1.515333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>192.408465</td>\n",
       "      <td>112.875642</td>\n",
       "      <td>6.817279</td>\n",
       "      <td>217.503394</td>\n",
       "      <td>57.419242</td>\n",
       "      <td>1600.238163</td>\n",
       "      <td>24.573931</td>\n",
       "      <td>17.850203</td>\n",
       "      <td>35.096258</td>\n",
       "      <td>1370.782364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321926</td>\n",
       "      <td>0.261278</td>\n",
       "      <td>0.037529</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140339</td>\n",
       "      <td>0.123589</td>\n",
       "      <td>0.098872</td>\n",
       "      <td>0.499853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2169.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-123.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2896.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1271.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1154.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3027.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2263.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3163.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>3666.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2672.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3675.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1343.000000</td>\n",
       "      <td>554.000000</td>\n",
       "      <td>6890.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>6853.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  2837.000000  2837.000000  2837.000000  2837.000000  2837.000000   \n",
       "mean   3017.875220   155.593232    12.850899   277.732464    43.927388   \n",
       "std     192.408465   112.875642     6.817279   217.503394    57.419242   \n",
       "min    2169.000000     0.000000     0.000000     0.000000  -123.000000   \n",
       "25%    2896.000000    58.000000     8.000000   108.000000     6.000000   \n",
       "50%    3027.000000   123.000000    12.000000   234.000000    26.000000   \n",
       "75%    3163.000000   266.000000    17.000000   391.000000    63.000000   \n",
       "max    3675.000000   359.000000    45.000000  1343.000000   554.000000   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  2837.000000  2837.000000  2837.000000  2837.000000  2837.000000  ...   \n",
       "mean   2583.450828   213.277053   224.611562   143.671836  2108.287980  ...   \n",
       "std    1600.238163    24.573931    17.850203    35.096258  1370.782364  ...   \n",
       "min      30.000000    86.000000   115.000000     0.000000    30.000000  ...   \n",
       "25%    1271.000000   201.000000   215.000000   123.000000  1154.000000  ...   \n",
       "50%    2263.000000   218.000000   227.000000   143.000000  1848.000000  ...   \n",
       "75%    3666.000000   231.000000   237.000000   168.000000  2672.000000  ...   \n",
       "max    6890.000000   254.000000   254.000000   248.000000  6853.000000  ...   \n",
       "\n",
       "                45           46           47           48           49  \\\n",
       "count  2837.000000  2837.000000  2837.000000  2837.000000  2837.000000   \n",
       "mean      0.117378     0.073669     0.001410     0.000352     0.000352   \n",
       "std       0.321926     0.261278     0.037529     0.018775     0.018775   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           50           51           52           53           54  \n",
       "count  2837.0  2837.000000  2837.000000  2837.000000  2837.000000  \n",
       "mean      0.0     0.020092     0.015509     0.009870     1.515333  \n",
       "std       0.0     0.140339     0.123589     0.098872     0.499853  \n",
       "min       0.0     0.000000     0.000000     0.000000     1.000000  \n",
       "25%       0.0     0.000000     0.000000     0.000000     1.000000  \n",
       "50%       0.0     0.000000     0.000000     0.000000     2.000000  \n",
       "75%       0.0     0.000000     0.000000     0.000000     2.000000  \n",
       "max       0.0     1.000000     1.000000     1.000000     2.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "97GG-s4cHZeS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3bbf500450a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcover_X_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcover_X_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcover_X_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcover_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cover_X_train = scaler.fit_transform(cover_X_train)\n",
    "cover_X_test = scaler.transform(cover_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRnSXWqzKh3x"
   },
   "source": [
    "Stacking — еще один способ объединить несколько алгоритмов в один, который часто используется как в решении реальных задач из промышленной сферы, так и в конкурсах на платформах вроде Kaggle.  \n",
    "Подход использует понятие _базовых классификаторов_, каждый из которых независимо обучается на некотором (возможно одном и том же) множестве признаков, а также _мета-классификатора_, использующего предсказания базовых классификаторов как признаки.\n",
    "\n",
    "Для избежания переобучения будем разбивать обучающую выборку на фолды.  \n",
    "Например, фолды при разбиении на три части:  \n",
    "``==*``  \n",
    "``=*=``  \n",
    "``*==``  \n",
    "\n",
    "Это требуется для того, чтобы получить новые признаки (ответы алгоритмов на первом уровне) на всей обучающей выборке, т.е. ответы алгоритма на тех объектах, которые не были использованы во время обучения. В примере выше мы будем использовать ответы алгоритма, полученные на объектах звездочках. _Важно_: на каждом фолде мы обучаем алгоритм заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734     2\n",
       "9574    2\n",
       "1409    1\n",
       "102     2\n",
       "9684    2\n",
       "       ..\n",
       "8210    1\n",
       "6481    2\n",
       "493     2\n",
       "1355    1\n",
       "769     2\n",
       "Name: 54, Length: 1418, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "splits = cv.split(train_X)\n",
    "for each in splits:\n",
    "    print(len(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "hcomzpKcHZeU"
   },
   "outputs": [],
   "source": [
    "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Computes meta-features using the classifier.\n",
    "    \n",
    "    :arg clf: scikit-learn classifier\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    # we check how many variables we have in the target column\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    # create an array where #rows - the # of rows in the original y_train and the #columns - the # of the classes in the target feature\n",
    "    X_meta_train = np.zeros((len(y_train), n_classes), dtype=np.float32)\n",
    "\n",
    "    splits = cv.split(X_train)\n",
    "    for train_fold_index, predict_fold_index in splits:\n",
    "        # for each iteration we get different indices for the train and test data\n",
    "        X_fold_train, y_fold_train = X_train[train_fold_index], y_train[train_fold_index]\n",
    "        X_fold_predict = X_train[predict_fold_index]\n",
    "        \n",
    "        folded_clf = clone(clf)\n",
    "        folded_clf.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
    "    \n",
    "    meta_clf = clone(clf)\n",
    "    meta_clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_meta_test = meta_clf.predict_proba(X_test)\n",
    "    \n",
    "    return X_meta_train, X_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature_mean(clf, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Эта функция подсчитывает признаки для мета-классификатора. \n",
    "    Они являются вероятностями классов при решении задачи многоклассовой классификации.\n",
    "\n",
    "    :arg clf: классификатор\n",
    "    :args X_train, y_train: обучающая выборка\n",
    "    :arg X_test: признаки тестовой выборки\n",
    "    :arg cv: класс, генерирующий фолды (KFold)\n",
    "\n",
    "    :returns X_meta_train, X_meta_test: новые признаки для обучающей и тестовой выборок\n",
    "    \"\"\"\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    X_meta_train = np.zeros((len(X_train), n_classes), dtype=np.float32)\n",
    "    X_meta_test = np.zeros((len(X_test), n_classes), dtype=np.float32)\n",
    "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "\n",
    "        folded_clf = clone(clf)\n",
    "        folded_clf.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
    "        X_meta_test += folded_clf.predict_proba(X_test)\n",
    "\n",
    "    X_meta_test /= cv.n_splits\n",
    "    \n",
    "    return X_meta_train, X_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "IcKj44HrHZeW"
   },
   "outputs": [],
   "source": [
    "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Generates metafeatures using a list of classifiers.\n",
    "    \n",
    "    :arg classifiers: list of scikit-learn classifiers\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
    "        for clf in tqdm(classifiers)\n",
    "    ]\n",
    "    \n",
    "    stacked_features_train = np.hstack([\n",
    "        features_train for features_train, features_test in features\n",
    "    ])\n",
    "\n",
    "    stacked_features_test = np.hstack([\n",
    "        features_test for features_train, features_test in features\n",
    "    ])\n",
    "    \n",
    "    return stacked_features_train, stacked_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4V6xy7_0HZeY"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Gbv7YXs8HZea",
    "outputId": "35cd300d-f3f9-4055-9967-3dc70b434e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7914023960535589"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=300)\n",
    "clf.fit(cover_X_train, cover_y_train)\n",
    "\n",
    "accuracy_score(clf.predict(cover_X_test), cover_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NmrhIV1aHZec",
    "outputId": "b9817055-7d57-46bd-f66e-8f0bff9c42b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:14<00:00,  3.65s/it]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    LogisticRegression(C=0.001, penalty='l1', solver='liblinear', max_iter=5000),\n",
    "    LogisticRegression(C=0.001, penalty='l2', solver='liblinear', max_iter=5000),  \n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    GradientBoostingClassifier(n_estimators=300)\n",
    "], cover_X_train, cover_X_test, cover_y_train.values, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KAqWN10ZHZee"
   },
   "outputs": [],
   "source": [
    "total_features_train = np.hstack([cover_X_train, stacked_features_train])\n",
    "total_features_test = np.hstack([cover_X_test, stacked_features_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "B-wCuCCdHZef",
    "outputId": "1a3137a3-815b-47ea-9fa1-639d4b2bebc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8083157152924595"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', solver='lbfgs')\n",
    "clf.fit(stacked_features_train, cover_y_train)\n",
    "accuracy_score(clf.predict(stacked_features_test), cover_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████                                                            | 2/4 [00:00<00:00, 10.99it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████                              | 3/4 [00:06<00:01,  1.89s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:12<00:00,  3.10s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.806864"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    LogisticRegression(C=0.001, penalty='l1', solver='saga', multi_class='ovr', max_iter=2000),\n",
    "    LogisticRegression(C=0.001, penalty='l2', solver='saga', multi_class='multinomial', max_iter=2000),\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    GradientBoostingClassifier(n_estimators=200)\n",
    "], cover_X_train, cover_X_test, cover_y_train.values, cv)\n",
    "\n",
    "total_features_train = np.hstack([cover_X_train, stacked_features_train])\n",
    "total_features_test = np.hstack([cover_X_test, stacked_features_test])\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', multi_class='auto', solver='lbfgs')\n",
    "# clf.fit(stacked_features_train, cover_y_train)\n",
    "# new_features = clf.predict(stacked_features_test)\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=cover_y_train,  X_test=stacked_features_test, y_test=cover_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier, ExtraTreesClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [02:38<00:00, 39.63s/it]\n",
      "c:\\users\\voytik\\anaconda3\\envs\\ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.982421"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    LogisticRegression(C=0.001, penalty='l1', solver='saga', multi_class='ovr', max_iter=2000),\n",
    "    LogisticRegression(C=0.001, penalty='l2', solver='saga', multi_class='multinomial', max_iter=2000),\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    GradientBoostingClassifier(n_estimators=200)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "# total_features_train = np.hstack([X_train, stacked_features_train])\n",
    "# total_features_test = np.hstack([X_test, stacked_features_test])\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', multi_class='auto', solver='lbfgs')\n",
    "# clf.fit(stacked_features_train, cover_y_train)\n",
    "# new_features = clf.predict(stacked_features_test)\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:11<00:00,  5.75s/it]\n",
      "c:\\users\\voytik\\anaconda3\\envs\\ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.987157"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=200, n_jobs=-1)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', multi_class='auto', solver='lbfgs')\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.88s/it]\n",
      "c:\\users\\voytik\\anaconda3\\envs\\ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9878"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', multi_class='auto', solver='lbfgs')\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:47<00:00, 11.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.989752"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    LogisticRegression(C=0.001, penalty='l1', solver='saga', multi_class='ovr', max_iter=2000),\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1),\n",
    "    AdaBoostClassifier(random_state=42)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "# total_features_train = np.hstack([X_train, stacked_features_train])\n",
    "# total_features_test = np.hstack([X_test, stacked_features_test])\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', multi_class='auto', solver='lbfgs')\n",
    "# clf.fit(stacked_features_train, cover_y_train)\n",
    "# new_features = clf.predict(stacked_features_test)\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only for the stratified example\n",
    "# def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
    "#     \"\"\"\n",
    "#     Computes meta-features using the classifier.\n",
    "    \n",
    "#     :arg clf: scikit-learn classifier\n",
    "#     :args X_train, y_train: training set\n",
    "#     :arg X_test: testing set\n",
    "#     :arg cv: cross-validation folding\n",
    "#     \"\"\"\n",
    "#     # we check how many variables we have in the target column\n",
    "#     n_classes = len(np.unique(y_train))\n",
    "#     # create an array where #rows - the # of rows in the original y_train and the #columns - the # of the classes in the target feature\n",
    "#     X_meta_train = np.zeros((len(y_train), n_classes), dtype=np.float32)\n",
    "\n",
    "#     splits = cv.split(X_train, y_train)\n",
    "#     for train_fold_index, predict_fold_index in splits:\n",
    "#         # for each iteration we get different indices for the train and test data\n",
    "#         X_fold_train, y_fold_train = X_train[train_fold_index], y_train[train_fold_index]\n",
    "#         X_fold_predict = X_train[predict_fold_index]\n",
    "        \n",
    "#         folded_clf = clone(clf)\n",
    "#         folded_clf.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "#         X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
    "    \n",
    "#     meta_clf = clone(clf)\n",
    "#     meta_clf.fit(X_train, y_train)\n",
    "    \n",
    "#     X_meta_test = meta_clf.predict_proba(X_test)\n",
    "    \n",
    "#     return X_meta_train, X_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                 | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████▌                                                                    | 1/2 [00:07<00:07,  7.29s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.52s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.981637"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', multi_class='auto', solver='lbfgs')\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                 | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████▌                                                                    | 1/2 [00:12<00:12, 12.88s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:23<00:00, 11.69s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.983371"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', multi_class='auto', solver='lbfgs')\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                 | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████▌                                                                    | 1/2 [00:04<00:04,  4.63s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.54s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.982334"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                 | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████▌                                                                    | 1/2 [00:03<00:03,  3.66s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.38s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.986659"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                 | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████▌                                                                    | 1/2 [00:02<00:02,  2.48s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.28s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.982528"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=24, n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = ExtraTreesClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "def compute_metric(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\n",
    "\n",
    "compute_metric(clf, X_train=stacked_features_train, y_train=y_train,  X_test=stacked_features_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976259"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=24, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf.predict_proba(X_test)\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=300, n_jobs=-1)\n",
    "et.fit(X_train, y_train)\n",
    "et_y_test_pred = et.predict_proba(X_test)\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_y_test_pred = lr.predict_proba(X_test)\n",
    "\n",
    "y_test_pred = (rf_y_test_pred + et_y_test_pred + lr_y_test_pred).argmax(axis=1)\n",
    "np.round(f1_score(y_test, y_test_pred, average='macro'), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m6.5_Практика.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
